# hyperparam_combi = [("lstm", 1, 64, 16, 0.5)]
lstm:
  llayer: 1 # [1, 2]
  lnode: 64 #[16, 32, 64]
  fnode: 16 #[16, 32, 64, 128]
  droprate: 0.5 #[0.2, 0.5]

# hyperparam_combi = [("gbm", 2000, 0.04, 5, 2, 0.4, 0.5, 0.5)]
gbm:
  n_estimators: 2000 # [2000]  # d=100
  learning_rate: 0.04 #[0.02, 0.04, 0.08]  # d=0.3, r=0.01~0.2
  max_depth: 5 #[3, 4, 5]  # d=6, r=1~10
  min_child_weight: 2 #[1, 2, 4]  # d=1
  gamma: 0.4 #[0, 0.2, 0.4]  # d=0, r=0~0.5
  subsample: 0.5 #[0.5, 0.8]  # d=1, r=0.5~0.9
  colsample_bytree: 0.5 #[0.5, 0.8]  # d=1, r=0.5~0.9

# hyperparam_combi = [("transformer", 64, 3, 32, 32, 1, 3, 0.2, 5, 4, "max")]
transformer:
  nfilt: 64 #[16, 32, 64]
  nhead: 3 #[2, 3, 4]
  kdim: 32 #[16, 32, 64]
  fnode: 32 #[32, 64, 128]
  clayer: 1 #[1, 2, 3, 4]
  tlayer: 3 #[1, 2, 3]
  droprate: 0.2 #[0.1, 0.2]
  filtsize: 5 #[5, 7, 9, 11]
  poolsize: 4  #[2, 4, 8]
  pooltype: "max" #["max"]

inception:
  nb_filters: 16
  use_residual: True
  use_bottleneck: True
  bottleneck_size: 32
  depth: 6
  kernel_size: 20

dataloader:
  n_splits: 5
  use_demo: True
  batch_size: 32
  sampling_rate: 0.01
  split_ratio: 0.2

train_param:
  init_lr: 1.0e-3
  num_epochs: 10
  input_shape: [30, 6]
  demo_shape: 3
  batch_size: 1024
  category_name : "age"
  category : 3
  window_size : 30
  sample_interval : 1